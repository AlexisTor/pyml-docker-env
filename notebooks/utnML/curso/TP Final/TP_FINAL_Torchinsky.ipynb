{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "89cc5048-d510-4244-b639-436372cf3777",
   "metadata": {},
   "source": [
    "# Trabajo Practico FINAL\n",
    "Participantes:\n",
    "Alexis Aramis Torchinsky"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "41d956d4-4475-4c31-a078-42c2513c39bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "### 1) Construya 2 datasets, uno con los datos originales y otro con los datos escalados y/o normalizados. \n",
    "### Divida ambos datasets en conjuntos de entrenamiento y de validación.\n",
    "#Imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn.model_selection\n",
    "from sklearn import preprocessing\n",
    "from sklearn.datasets import load_wine\n",
    "\n",
    "# carga del dataload orginal de Wine recognition dataset\n",
    "wine=load_wine()\n",
    "etiquetas=wine.target\n",
    "#print(etiquetas)\n",
    "originalData = pd.DataFrame(wine.data)\n",
    "#print(\"Original Wine Data\")\n",
    "#print(originalData)\n",
    "#Conjuntos de Entrenamiento y Validacion de Datos Originales\n",
    "OrigD_X_train, OrigD_X_test, OrigD_y_train, OrigD_y_test=sklearn.model_selection.train_test_split(\n",
    "        originalData,\n",
    "        range(len(originalData)),\n",
    "        test_size=0.2,\n",
    "        shuffle=True)\n",
    "TagOrigD_y_train=etiquetas[OrigD_y_train]\n",
    "TagOrigD_y_test=etiquetas[OrigD_y_test]\n",
    "#print(TagOrigD_y_train)\n",
    "#print(TagOrigD_y_test)\n",
    "#Conjuntos de Entrenamiento y Validacion de Datos Normalizados\n",
    "normalizedData=preprocessing.normalize(originalData,norm='l1',axis=0)\n",
    "#print(\"Normalized Wine data\")\n",
    "#print(normalizedData)\n",
    "NormD_X_train, NormD_X_test, NormD_y_train, NormD_y_test=sklearn.model_selection.train_test_split(\n",
    "        normalizedData,\n",
    "        range(len(originalData)),\n",
    "        test_size=0.2,\n",
    "        shuffle=True)\n",
    "TagNormD_y_train=etiquetas[NormD_y_train]\n",
    "TagNormD_y_test=etiquetas[NormD_y_test]\n",
    "#print(TagNormD_y_train)\n",
    "#print(TagNormD_y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "484efc15-f5ca-47fe-961f-553a33b444c1",
   "metadata": {},
   "source": [
    "# Analisis por metodo KNN\n",
    "Elija un valor de K y aplique el algoritmo de KNN en ambos datasets. \n",
    "\n",
    "Evalúe la precisión en ambos casos sobre el conjunto de validación correspondiente. \n",
    "\n",
    "Analice brevemente los resultados obtenidos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "12a4f391-1bca-4a7d-807e-c54ef749f1fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "neighbors calculados como Raiz de la longitud del dataset: 6\n",
      "=========================================================\n",
      "-------- Analisis por KNN sobre datos originales --------\n",
      "Prediccion por uniform\n",
      "[1 0 0 0 2 2 0 2 1 1 1 0 2 2 2 1 0 1 0 1 0 1 2 0 1 0 0 0 0 2 0 0 1 2 1 0]\n",
      "[1 0 0 0 1 2 0 2 1 2 1 0 2 2 2 2 0 1 2 1 2 1 2 0 2 1 0 2 2 2 2 0 2 2 1 0]\n",
      "Presicion: 0.6944444444444444\n",
      "Prediccion por distance\n",
      "[1 0 0 0 2 2 0 2 1 1 1 0 2 2 2 1 0 1 0 1 0 1 2 0 1 0 0 0 0 2 0 0 1 2 1 0]\n",
      "[1 0 0 0 1 2 0 2 1 2 1 0 2 2 2 2 0 1 1 1 1 1 2 0 2 0 0 2 2 2 2 0 2 2 1 0]\n",
      "Presicion: 0.7222222222222222\n",
      "=========================================================\n",
      "=========================================================\n",
      "-------- Analisis por KNN sobre datos NORMALIZADOS --------\n",
      "Prediccion por uniform\n",
      "[2 1 0 1 0 2 0 1 0 0 1 0 0 2 1 2 1 1 0 2 1 1 2 1 2 1 1 2 1 1 2 0 0 0 0 0]\n",
      "[2 1 0 1 0 2 0 1 0 0 1 0 0 2 1 2 0 1 0 2 1 1 2 1 2 1 1 2 0 1 2 0 0 0 0 0]\n",
      "Presicion: 0.9444444444444444\n",
      "Prediccion por distance\n",
      "[2 1 0 1 0 2 0 1 0 0 1 0 0 2 1 2 1 1 0 2 1 1 2 1 2 1 1 2 1 1 2 0 0 0 0 0]\n",
      "[2 1 0 1 0 2 0 1 0 0 1 0 0 2 1 2 1 1 0 2 1 1 2 1 2 1 1 2 1 1 2 0 0 0 0 0]\n",
      "Presicion: 1.0\n",
      "=========================================================\n"
     ]
    }
   ],
   "source": [
    "#Imports\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "from sklearn import neighbors, datasets\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "### Setup de KNN\n",
    "sc_X=StandardScaler()\n",
    "#OrigD_X_train=sc_X.fit_transform(OrigD_X_train)\n",
    "#OrigD_X_test=sc_X.fit_transform(OrigD_X_test)\n",
    "import math\n",
    "n_neighbors = int(math.sqrt(len(OrigD_y_test))) #15\n",
    "#n_neighbors=15\n",
    "print(f\"neighbors calculados como Raiz de la longitud del dataset: {n_neighbors}\")\n",
    "### Aplicamos el modelo KNN para el DS Original de training\n",
    "print(\"=========================================================\")\n",
    "print(\"-------- Analisis por KNN sobre datos originales --------\")\n",
    "for weights in ['uniform', 'distance']:\n",
    "    # Creamos una instancia del clasificador de vecinos más cercanos y le pasamos los datos mediante fit().\n",
    "    # base sobre dataset Original de TRainig(OTR)\n",
    "    classifierOTR = neighbors.KNeighborsClassifier(n_neighbors, weights=weights, metric='euclidean')\n",
    "    classifierOTR.fit(OrigD_X_train, TagOrigD_y_train)\n",
    "    \n",
    "    predictOTR = classifierOTR.predict(OrigD_X_test)\n",
    "    print(f\"Prediccion por {weights}\")\n",
    "    print(TagOrigD_y_test)\n",
    "    print(predictOTR)\n",
    "    print(f\"Presicion: {accuracy_score(TagOrigD_y_test, predictOTR)}\")\n",
    "print(\"=========================================================\")\n",
    "\n",
    "\n",
    "### Aplicamos el modelo KNN para el DS Normalizados de training\n",
    "print(\"=========================================================\")\n",
    "print(\"-------- Analisis por KNN sobre datos NORMALIZADOS --------\")\n",
    "for weights in ['uniform', 'distance']:\n",
    "    # Creamos una instancia del clasificador de vecinos más cercanos y le pasamos los datos mediante fit().\n",
    "    # base sobre dataset Normalizado de TRainig(NTR)\n",
    "    classifierNTR = neighbors.KNeighborsClassifier(n_neighbors, weights=weights, metric='euclidean')\n",
    "    classifierNTR.fit(NormD_X_train, TagNormD_y_train)\n",
    "    \n",
    "    predictNTR = classifierNTR.predict(NormD_X_test)\n",
    "    print(f\"Prediccion por {weights}\")\n",
    "    print(TagNormD_y_test)\n",
    "    print(predictNTR)\n",
    "    print(f\"Presicion: {accuracy_score(TagNormD_y_test, predictNTR)}\")\n",
    "print(\"=========================================================\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83a30a96-8702-4186-b6d8-a6a661890ed0",
   "metadata": {},
   "source": [
    "## KNN: Breve analisis de los resultados\n",
    "Luego de varias ejecuciones depurando el kernel todas las presiciones obtenidas con los datos normalizados se encuentran por encima del 94%, mientras que los modelos entrenados sobre los datos originales sin preprosesar nunca super el 75% de la presicion.\n",
    "\n",
    "Asi mismo, en ambos entrenamientos(datos originales y datos normalizados) se ve una mejora consistente de la presicion(3 puntos para datos normalizados, 6 a 9 puntos porcentuales para datos originales) cuando se utiliza el pesaje con el metodo de \"inversa de la distancia\" versus el uniforme.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87ac8b4e-53d8-4f1f-a6be-97ab7d31c728",
   "metadata": {},
   "source": [
    "# Analisis por Arboles de desicion\n",
    "\n",
    "Elija un valor de max_depth y aplique el algoritmo de Árboles de Decisión en ambos datasets. \n",
    "\n",
    "Evalúe la precisión en ambos casos. sobre el conjunto de validación correspondiente. Analice brevemente los resultados obtenidos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dfd69f75-fbf9-4cef-a388-f49fbc258a88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score del Arbol sobre datos Originales de entrenamiento: 1.0\n",
      "Score del Arbol sobre datos Originales de test: 0.9444444444444444\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.tree import export_graphviz\n",
    "import graphviz\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "\n",
    "arbolOTR=DecisionTreeClassifier(max_depth=5)\n",
    "arbolOTR.fit(OrigD_X_train, TagOrigD_y_train)\n",
    "\n",
    "print(f\"Score del Arbol sobre datos Originales de entrenamiento: {arbolOTR.score(OrigD_X_train, TagOrigD_y_train)}\")\n",
    "\n",
    "print(f\"Score del Arbol sobre datos Originales de test: {arbolOTR.score(OrigD_X_test, TagOrigD_y_test)}\")\n",
    "\n",
    "#export_graphviz(\n",
    "#    arbolOTR, \n",
    "#    out_file='arbol1.dot', \n",
    "#    class_names=wine.target_names, \n",
    "#    feature_names=wine.feature_names, \n",
    "#    impurity=False, \n",
    "#    filled=True)\n",
    "\n",
    "#with open('arbol1.dot') as f:\n",
    "#    dot_graph=f.read()\n",
    "\n",
    "#graphviz.Source(dot_graph)\n",
    "\n",
    "#from sklearn.tree import plot_tree\n",
    "#plot_tree(arbolOTR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4df2cbc0-b089-4b3b-91f0-64bd24c419ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score del Arbol sobre datos Normalizados de entrenamiento: 1.0\n",
      "Score del Arbol sobre datos Normalizados de test: 0.9444444444444444\n"
     ]
    }
   ],
   "source": [
    "arbolNTR=DecisionTreeClassifier(max_depth=5)\n",
    "arbolNTR.fit(NormD_X_train, TagNormD_y_train)\n",
    "\n",
    "print(f\"Score del Arbol sobre datos Normalizados de entrenamiento: {arbolNTR.score(NormD_X_train, TagNormD_y_train)}\")\n",
    "\n",
    "print(f\"Score del Arbol sobre datos Normalizados de test: {arbolNTR.score(NormD_X_test, TagNormD_y_test)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83578791-c774-41cf-a900-e05508f9e878",
   "metadata": {},
   "source": [
    "## Arboles de Desicion: Breve analisis de los resultados\n",
    "Luego de varias ejecuciones depurando el kernel todas las presiciones obtenidas para el dataset de validacion tanto con los datos originales como los normalizados se mantienen en un 94,4%. El mismo nivel de presicion se da tanto para una profundidad de 3 y de 5 niveles. Con lo que se podria concluir que es analisis por arboles de desicion para este modelo es sumamente consistente.\n",
    "Tambien ya se visualiza que para este dataset el modelo KNN obtiene mejor score que los Arboles aunque menos consistente.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c1a756b-8b96-4546-846a-fa912e00b948",
   "metadata": {},
   "source": [
    "# Analisis por PCA\n",
    "\n",
    "Aplique el algoritmo PCA a los datos escalados y/o normalizados para reducir su dimensionalidad a 2, y grafique el conjunto resultante."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2ffa9d42-1507-4535-b0b2-d6d22c49a67c",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (3331713977.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[9], line 1\u001b[0;36m\u001b[0m\n\u001b[0;31m    install mglearn\u001b[0m\n\u001b[0m            ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "install mglearn\n",
    "import mglearn\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
