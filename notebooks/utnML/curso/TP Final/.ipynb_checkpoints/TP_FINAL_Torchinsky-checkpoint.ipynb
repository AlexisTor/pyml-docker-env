{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "89cc5048-d510-4244-b639-436372cf3777",
   "metadata": {},
   "source": [
    "# Trabajo Practico FINAL\n",
    "Participantes:\n",
    "Alexis Aramis Torchinsky"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "41d956d4-4475-4c31-a078-42c2513c39bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "### 1) Construya 2 datasets, uno con los datos originales y otro con los datos escalados y/o normalizados. \n",
    "### Divida ambos datasets en conjuntos de entrenamiento y de validación.\n",
    "#Imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn.model_selection\n",
    "from sklearn import preprocessing\n",
    "from sklearn.datasets import load_wine\n",
    "\n",
    "# carga del dataload orginal de Wine recognition dataset\n",
    "wine=load_wine()\n",
    "etiquetas=wine.target\n",
    "#print(etiquetas)\n",
    "originalData = pd.DataFrame(wine.data)\n",
    "#print(\"Original Wine Data\")\n",
    "#print(originalData)\n",
    "#Conjuntos de Entrenamiento y Validacion de Datos Originales\n",
    "OrigD_X_train, OrigD_X_test, OrigD_y_train, OrigD_y_test=sklearn.model_selection.train_test_split(\n",
    "        originalData,\n",
    "        range(len(originalData)),\n",
    "        test_size=0.2,\n",
    "        shuffle=True)\n",
    "TagOrigD_y_train=etiquetas[OrigD_y_train]\n",
    "TagOrigD_y_test=etiquetas[OrigD_y_test]\n",
    "#print(TagOrigD_y_train)\n",
    "#print(TagOrigD_y_test)\n",
    "#Conjuntos de Entrenamiento y Validacion de Datos Normalizados\n",
    "normalizedData=preprocessing.normalize(originalData,norm='l1',axis=0)\n",
    "#print(\"Normalized Wine data\")\n",
    "#print(normalizedData)\n",
    "NormD_X_train, NormD_X_test, NormD_y_train, NormD_y_test=sklearn.model_selection.train_test_split(\n",
    "        normalizedData,\n",
    "        range(len(originalData)),\n",
    "        test_size=0.2,\n",
    "        shuffle=True)\n",
    "TagNormD_y_train=etiquetas[NormD_y_train]\n",
    "TagNormD_y_test=etiquetas[NormD_y_test]\n",
    "#print(TagNormD_y_train)\n",
    "#print(TagNormD_y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "484efc15-f5ca-47fe-961f-553a33b444c1",
   "metadata": {},
   "source": [
    "# Analisis por metodo KNN\n",
    "Elija un valor de K y aplique el algoritmo de KNN en ambos datasets. \n",
    "\n",
    "Evalúe la precisión en ambos casos sobre el conjunto de validación correspondiente. \n",
    "\n",
    "Analice brevemente los resultados obtenidos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "12a4f391-1bca-4a7d-807e-c54ef749f1fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "neighbors calculados como Raiz de la longitud del dataset: 6\n",
      "=========================================================\n",
      "-------- Analisis por KNN sobre datos originales --------\n",
      "Prediccion por uniform\n",
      "[0 0 2 0 1 0 2 1 2 1 0 1 0 0 0 2 1 1 1 0 1 0 1 2 0 1 0 1 1 0 2 2 2 0 1 0]\n",
      "[0 0 2 0 2 0 2 1 1 1 0 0 0 0 0 1 1 2 1 0 1 0 1 2 0 1 0 1 1 2 1 2 2 0 1 0]\n",
      "Presicion: 0.8055555555555556\n",
      "Prediccion por distance\n",
      "[0 0 2 0 1 0 2 1 2 1 0 1 0 0 0 2 1 1 1 0 1 0 1 2 0 1 0 1 1 0 2 2 2 0 1 0]\n",
      "[2 0 2 0 2 0 2 1 2 1 0 0 0 0 0 1 1 2 1 0 1 1 1 2 0 1 0 2 2 2 2 2 2 1 1 0]\n",
      "Presicion: 0.7222222222222222\n",
      "=========================================================\n",
      "=========================================================\n",
      "-------- Analisis por KNN sobre datos NORMALIZADOS --------\n",
      "Prediccion por uniform\n",
      "[1 0 1 0 1 0 2 0 0 0 0 1 0 0 1 0 1 2 0 2 2 0 2 2 0 2 1 0 0 2 1 2 0 1 0 1]\n",
      "[1 0 1 0 1 0 2 0 0 0 0 1 0 0 1 0 1 2 0 2 2 0 2 2 0 2 1 0 0 2 1 2 0 1 0 1]\n",
      "Presicion: 1.0\n",
      "Prediccion por distance\n",
      "[1 0 1 0 1 0 2 0 0 0 0 1 0 0 1 0 1 2 0 2 2 0 2 2 0 2 1 0 0 2 1 2 0 1 0 1]\n",
      "[1 0 1 0 1 0 2 0 0 0 0 1 0 0 1 0 1 2 0 2 2 0 2 2 0 2 1 0 0 2 1 2 0 1 0 1]\n",
      "Presicion: 1.0\n",
      "=========================================================\n"
     ]
    }
   ],
   "source": [
    "#Imports\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "from sklearn import neighbors, datasets\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "### Setup de KNN\n",
    "sc_X=StandardScaler()\n",
    "#OrigD_X_train=sc_X.fit_transform(OrigD_X_train)\n",
    "#OrigD_X_test=sc_X.fit_transform(OrigD_X_test)\n",
    "import math\n",
    "n_neighbors = int(math.sqrt(len(OrigD_y_test))) #15\n",
    "#n_neighbors=15\n",
    "print(f\"neighbors calculados como Raiz de la longitud del dataset: {n_neighbors}\")\n",
    "### Aplicamos el modelo KNN para el DS Original de training\n",
    "print(\"=========================================================\")\n",
    "print(\"-------- Analisis por KNN sobre datos originales --------\")\n",
    "for weights in ['uniform', 'distance']:\n",
    "    # Creamos una instancia del clasificador de vecinos más cercanos y le pasamos los datos mediante fit().\n",
    "    # base sobre dataset Original de TRainig(OTR)\n",
    "    classifierOTR = neighbors.KNeighborsClassifier(n_neighbors, weights=weights, metric='euclidean')\n",
    "    classifierOTR.fit(OrigD_X_train, TagOrigD_y_train)\n",
    "    \n",
    "    predictOTR = classifierOTR.predict(OrigD_X_test)\n",
    "    print(f\"Prediccion por {weights}\")\n",
    "    print(TagOrigD_y_test)\n",
    "    print(predictOTR)\n",
    "    print(f\"Presicion: {accuracy_score(TagOrigD_y_test, predictOTR)}\")\n",
    "print(\"=========================================================\")\n",
    "\n",
    "\n",
    "### Aplicamos el modelo KNN para el DS Normalizados de training\n",
    "print(\"=========================================================\")\n",
    "print(\"-------- Analisis por KNN sobre datos NORMALIZADOS --------\")\n",
    "for weights in ['uniform', 'distance']:\n",
    "    # Creamos una instancia del clasificador de vecinos más cercanos y le pasamos los datos mediante fit().\n",
    "    # base sobre dataset Normalizado de TRainig(NTR)\n",
    "    classifierNTR = neighbors.KNeighborsClassifier(n_neighbors, weights=weights, metric='euclidean')\n",
    "    classifierNTR.fit(NormD_X_train, TagNormD_y_train)\n",
    "    \n",
    "    predictNTR = classifierNTR.predict(NormD_X_test)\n",
    "    print(f\"Prediccion por {weights}\")\n",
    "    print(TagNormD_y_test)\n",
    "    print(predictNTR)\n",
    "    print(f\"Presicion: {accuracy_score(TagNormD_y_test, predictNTR)}\")\n",
    "print(\"=========================================================\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83a30a96-8702-4186-b6d8-a6a661890ed0",
   "metadata": {},
   "source": [
    "# Breve analisis de los resultados\n",
    "Luego de varias ejecuciones depurando el kernel todas las presiciones obtenidas con los datos normalizados se encuentran por encima del 97%, mientras que los modelos entrenados sobre los datos originales sin preprosesar nunca super el 75% de la presicion.\n",
    "\n",
    "Asi mismo, en ambos entrenamientos(datos originales y datos normalizados) se ve una mejora consistente de la presicion(3 puntos para datos normalizados, 6 a 9 puntos porcentuales para datos originales) cuando se utiliza el pesaje con el metodo de \"inversa de la distancia\" versus el uniforme.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87ac8b4e-53d8-4f1f-a6be-97ab7d31c728",
   "metadata": {},
   "source": [
    "# Analisis por Arboles de desicion\n",
    "\n",
    "Elija un valor de max_depth y aplique el algoritmo de Árboles de Decisión en ambos datasets. \n",
    "\n",
    "Evalúe la precisión en ambos casos. sobre el conjunto de validación correspondiente. Analice brevemente los resultados obtenidos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dfd69f75-fbf9-4cef-a388-f49fbc258a88",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'graphviz'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtree\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DecisionTreeClassifier\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtree\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m export_graphviz\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mgraphviz\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcolors\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ListedColormap\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'graphviz'"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.tree import export_graphviz\n",
    "import graphviz\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "\n",
    "arbolOTR=DecisionTreeClassifier(max_depth=3)\n",
    "arbolOTR.fit(OrigD_X_train, TagOrigD_y_train)\n",
    "\n",
    "print(f\"Score del Arbol sobre datos de entrenamiento: {arbolOTR.score(OrigD_X_train, TagOrigD_y_train)}\")\n",
    "\n",
    "print(f\"Score del Arbol sobre datos de test: {arbolOTR.score(OrigD_X_test, TagOrigD_y_test)}\")\n",
    "\n",
    "export_graphviz(\n",
    "    arbolOTR, \n",
    "    out_file='arbol1.dot', \n",
    "    class_names=wine.target_names, \n",
    "    feature_names=wine.feature_names, \n",
    "    impurity=False, \n",
    "    filled=True)\n",
    "\n",
    "with open('arbol1.dot') as f:\n",
    "    dot_graph=f.read()\n",
    "\n",
    "graphviz.Source(dot_graph)\n",
    "\n",
    "from sklearn.tree import plot_tree\n",
    "plot_tree(arbol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e0e61c2-1476-4828-ac8f-09ab3a8a6ddd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
